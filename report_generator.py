"""
æŠ¥å‘Šç”Ÿæˆå™¨ - ä½¿ç”¨ç­–ç•¥æ¨¡å¼å’Œå·¥å‚æ¨¡å¼å®ç°æœˆæŠ¥å’Œchangelogçš„ç”Ÿæˆ

ä¸»è¦è®¾è®¡æ¨¡å¼:
1. ç­–ç•¥æ¨¡å¼: ä¸åŒç±»å‹æŠ¥å‘Šä½¿ç”¨ä¸åŒçš„ç”Ÿæˆç­–ç•¥
2. æ¨¡æ¿æ–¹æ³•æ¨¡å¼: å®šä¹‰æŠ¥å‘Šç”Ÿæˆçš„åŸºæœ¬æµç¨‹
3. å·¥å‚æ¨¡å¼: åˆ›å»ºä¸åŒç±»å‹çš„æŠ¥å‘Šç”Ÿæˆå™¨
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
import json
import os
from qwen_agent.agents import Assistant
from dataclasses import dataclass
from enum import Enum


class PRType(Enum):
    """PRç±»å‹æšä¸¾"""
    FEATURE = "feature"
    BUGFIX = "bugfix"
    DOC = "doc"
    REFACTOR = "refactor"
    TEST = "test"


@dataclass
class PRInfo:
    """PRä¿¡æ¯æ•°æ®ç±»"""
    number: int
    title: str
    html_url: str
    user: Dict[str, Any]
    highlight: str = ""
    function_value: str = ""
    score: int = 0
    pr_type: Optional[PRType] = None


class ReportGeneratorInterface(ABC):
    """æŠ¥å‘Šç”Ÿæˆå™¨æ¥å£"""
    
    @abstractmethod
    def get_pr_list(self, **kwargs) -> List[PRInfo]:
        """è·å–PRåˆ—è¡¨ - ä¸åŒç±»å‹çš„æŠ¥å‘Šæœ‰ä¸åŒçš„è·å–æ–¹å¼"""
        pass
    
    @abstractmethod
    def analyze_prs_with_llm(self, pr_list: List[PRInfo]) -> List[PRInfo]:
        """ä½¿ç”¨LLMåˆ†æPRåˆ—è¡¨ - é€šç”¨é€»è¾‘"""
        pass
    
    @abstractmethod
    def generate_report(self, analyzed_prs: List[PRInfo]) -> str:
        """ç”ŸæˆæŠ¥å‘Š - ä¸åŒç±»å‹çš„æŠ¥å‘Šæœ‰ä¸åŒçš„æ ¼å¼"""
        pass
    
    def create_report(self, **kwargs) -> str:
        """æ¨¡æ¿æ–¹æ³• - å®šä¹‰æŠ¥å‘Šç”Ÿæˆçš„å®Œæ•´æµç¨‹"""
        # 1. è·å–PRåˆ—è¡¨
        pr_list = self.get_pr_list(**kwargs)
        
        # 2. ä½¿ç”¨LLMåˆ†æPR
        analyzed_prs = self.analyze_prs_with_llm(pr_list)
        
        # 3. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report(analyzed_prs)
        
        # 4. ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        self.save_report_to_file(report, "report.md")
        
        # 5. ç”Ÿæˆè‹±æ–‡ç¿»è¯‘
        if kwargs.get('translate', True):
            english_report = self.translate_to_english(report)
            self.save_report_to_file(english_report, "report.EN.md")
        
        return report
    
    def save_report_to_file(self, content: str, filename: str) -> None:
        """
        ä¿å­˜æŠ¥å‘Šå†…å®¹åˆ°æ–‡ä»¶
        
        Args:
            content: æŠ¥å‘Šå†…å®¹
            filename: æ–‡ä»¶å
        """
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶ {filename} å¤±è´¥: {str(e)}")
    
    def translate_to_english(self, content: str) -> str:
        """
        å°†æŠ¥å‘Šå†…å®¹ç¿»è¯‘æˆè‹±æ–‡
        
        Args:
            content: ä¸­æ–‡æŠ¥å‘Šå†…å®¹
            
        Returns:
            è‹±æ–‡ç¿»è¯‘å†…å®¹
        """
        print("ğŸŒ å¼€å§‹ç¿»è¯‘æŠ¥å‘Šä¸ºè‹±æ–‡...")
        
        translation_prompt = f"""
        è¯·å°†ä»¥ä¸‹ä¸­æ–‡æŠ¥å‘Šç¿»è¯‘æˆè‹±æ–‡ï¼Œä¿æŒmarkdownæ ¼å¼ä¸å˜ï¼Œå¹¶ç¡®ä¿æŠ€æœ¯æœ¯è¯­ç¿»è¯‘å‡†ç¡®ï¼š

        {content}

        ç¿»è¯‘è¦æ±‚ï¼š
        1. ä¿æŒæ‰€æœ‰markdownæ ¼å¼æ ‡è®°ï¼ˆ#ã€##ã€###ã€-ã€[]()ç­‰ï¼‰
        2. ä¿æŒæ‰€æœ‰é“¾æ¥å’ŒURLä¸å˜
        3. æŠ€æœ¯æœ¯è¯­ä½¿ç”¨å‡†ç¡®çš„è‹±æ–‡è¡¨è¾¾
        4. ä¿æŒä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£é£æ ¼
        5. ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–æ³¨é‡Š
        """
        
        messages = [{'role': 'user', 'content': translation_prompt}]
        
        try:
            response_text = self._get_llm_response(messages)
            print("âœ… ç¿»è¯‘å®Œæˆ")
            return response_text
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {str(e)}")
            return f"# Translation Error\n\nFailed to translate the report: {str(e)}\n\n---\n\n{content}"


class BaseReportGenerator(ReportGeneratorInterface):
    """æŠ¥å‘Šç”Ÿæˆå™¨åŸºç±» - å®ç°é€šç”¨é€»è¾‘"""
    
    def __init__(self):
        self.llm_assistant = self._create_llm_assistant()
    
    def _create_llm_assistant(self) -> Assistant:
        """åˆ›å»ºLLMåŠ©æ‰‹"""
        llm_cfg = {
            'model': os.getenv('MODEL_NAME'),
            'model_server': os.getenv('MODEL_SERVER'),
            'api_key': os.getenv('DASHSCOPE_API_KEY'),
        }
        return Assistant(llm=llm_cfg)
    
    def analyze_prs_with_llm(self, pr_list: List[PRInfo]) -> List[PRInfo]:
        """ä½¿ç”¨LLMåˆ†æPRåˆ—è¡¨ - é€šç”¨å®ç°"""
        analyzed_prs = []
        
        for pr in pr_list:
            try:
                # è°ƒç”¨LLMåˆ†æå•ä¸ªPR
                analyzed_pr = self._analyze_single_pr(pr)
                analyzed_prs.append(analyzed_pr)
            except Exception as e:
                print(f"åˆ†æPR #{pr.number}æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                analyzed_prs.append(pr)  # å¦‚æœåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹PR
        
        return analyzed_prs
    
    def _analyze_single_pr(self, pr: PRInfo) -> PRInfo:
        """åˆ†æå•ä¸ªPR - å­ç±»å¯ä»¥é‡å†™æ­¤æ–¹æ³•æ¥å®šåˆ¶åˆ†æé€»è¾‘"""
        # é»˜è®¤å®ç°ï¼šå¦‚æœå·²ç»æœ‰åˆ†æç»“æœå°±ç›´æ¥è¿”å›
        if pr.highlight and pr.function_value:
            return pr
        
        # å¦åˆ™ä½¿ç”¨åŸºç¡€åˆ†æï¼Œå­ç±»éœ€è¦æä¾›prompt
        prompt = self._get_analysis_prompt()
        return self._basic_pr_analysis(pr, prompt)
    
    def _get_analysis_prompt(self) -> str:
        """è·å–åˆ†æprompt - å­ç±»å¿…é¡»é‡å†™æ­¤æ–¹æ³•"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç° _get_analysis_prompt æ–¹æ³•")
    
    def _basic_pr_analysis(self, pr: PRInfo, analysis_prompt: str) -> PRInfo:
        """åŸºç¡€PRåˆ†æ - è°ƒç”¨MCPå·¥å…·è·å–PRè¯¦ç»†ä¿¡æ¯å¹¶åˆ†æ"""
        try:
            # 1. è·å–PRçš„è¯¦ç»†ä¿¡æ¯å’Œæ–‡ä»¶å˜æ›´
            pr_details = self._get_pr_detailed_info(pr.number)
            if not pr_details:
                print(f"æ— æ³•è·å–PR #{pr.number}çš„è¯¦ç»†ä¿¡æ¯")
                return pr
            
            # 2. å‡†å¤‡åˆ†ææ•°æ®
            pr_info = {
                "number": pr.number,
                "title": pr.title,
                "body": pr_details.get("body", "")[:500] if pr_details.get("body") else "",
                "total_changes": pr_details.get("total_changes", 0),
                "file_changes": pr_details.get("file_changes", [])
            }
            
            # 3. æ„å»ºå®Œæ•´çš„åˆ†æè¯·æ±‚
            full_prompt = analysis_prompt.format(
                pr_number=pr.number,
                pr_title=pr.title,
                pr_body=pr_info["body"],
                total_changes=pr_info["total_changes"],
                file_changes=json.dumps(pr_info["file_changes"][:5], indent=2, ensure_ascii=False)  # é™åˆ¶æ–‡ä»¶æ•°é‡
            )
            
            # 4. ä½¿ç”¨LLMåˆ†æ
            messages = [{'role': 'user', 'content': full_prompt}]
            response_text = self._get_llm_response(messages)
            
            # 5. è§£æç»“æœ
            result = json.loads(response_text)
            pr.highlight = result.get("highlight", pr.highlight)
            pr.function_value = result.get("function_value", pr.function_value)
            
            # 6. å¦‚æœåŒ…å«è¯„åˆ†ï¼Œè§£æè¯„åˆ†ï¼ˆæœˆæŠ¥ä¸“ç”¨ï¼‰
            if "score" in result:
                try:
                    pr.score = int(result.get("score", 0))
                except (ValueError, TypeError):
                    pr.score = 0
            
            # 7. å¦‚æœæ˜¯changelogï¼Œè¿˜è¦è§£æç±»å‹
            if hasattr(self, '_parse_pr_type') and "pr_type" in result:
                pr.pr_type = self._parse_pr_type(result.get("pr_type", "feature"))
            
            print(f"PR #{pr.number}åˆ†æå®Œæˆ")
            
        except Exception as e:
            print(f"LLMåˆ†æPR #{pr.number}å¤±è´¥: {str(e)}")
            # è®¾ç½®é»˜è®¤å€¼
            pr.highlight = pr.highlight or "æŠ€æœ¯æ›´æ–°"
            pr.function_value = pr.function_value or "åŠŸèƒ½æ”¹è¿›"
        
        return pr
    
    def _get_pr_detailed_info(self, pr_number: int) -> dict:
        """è·å–PRçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶å˜æ›´"""
        try:
            from utils.pr_helper import GitHubHelper
            github_helper = GitHubHelper()
            
            # è·å–PRåŸºæœ¬ä¿¡æ¯
            pr_info = github_helper.get_pull_request(
                owner="alibaba", 
                repo="higress", 
                pullNumber=pr_number
            )
            
            # è·å–PRæ–‡ä»¶å˜æ›´ä¿¡æ¯
            files_result = github_helper.get_pull_request_files(
                owner="alibaba", 
                repo="higress", 
                pullNumber=pr_number
            )
            
            if not isinstance(files_result, list):
                return {
                    "body": pr_info.get("body", "") if pr_info else "",
                    "total_changes": 0,
                    "file_changes": []
                }
                
            # è®¡ç®—æ€»å˜æ›´è¡Œæ•°
            total_changes = 0
            for file_info in files_result:
                total_changes += file_info.get("additions", 0) + file_info.get("deletions", 0)
            
            # å‡†å¤‡æ–‡ä»¶å˜æ›´ä¿¡æ¯
            file_changes = [
                {
                    "filename": file.get("filename", ""),
                    "additions": file.get("additions", 0),
                    "deletions": file.get("deletions", 0),
                    "patch": file.get("patch", "")[:200] if file.get("patch") else ""  # æˆªå–éƒ¨åˆ†patchå†…å®¹
                } for file in files_result[:10]  # é™åˆ¶æ–‡ä»¶æ•°é‡
            ]
            
            return {
                "body": pr_info.get("body", "") if pr_info else "",
                "total_changes": total_changes,
                "file_changes": file_changes
            }
            
        except Exception as e:
            print(f"è·å–PR #{pr_number}è¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {
                "body": "",
                "total_changes": 0,
                "file_changes": []
            }
    
    def _get_llm_response(self, messages: List[Dict[str, str]]) -> str:
        """è·å–LLMå“åº”"""
        collected_responses = []
        for response in self.llm_assistant.run(messages=messages):
            if isinstance(response, list) and len(response) > 0:
                for msg in response:
                    if msg.get('role') == 'assistant' and msg.get('content'):
                        collected_responses.append(msg.get('content', ""))
        
        return collected_responses[-1] if collected_responses else ""


class ReportGeneratorFactory:
    """æŠ¥å‘Šç”Ÿæˆå™¨å·¥å‚ç±»"""
    
    @staticmethod
    def create_generator(report_type: str) -> ReportGeneratorInterface:
        """åˆ›å»ºæŒ‡å®šç±»å‹çš„æŠ¥å‘Šç”Ÿæˆå™¨"""
        if report_type.lower() == "monthly":
            from monthly_report_generator import MonthlyReportGenerator
            return MonthlyReportGenerator()
        elif report_type.lower() == "changelog":
            from changelog_generator import ChangelogReportGenerator
            return ChangelogReportGenerator()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æŠ¥å‘Šç±»å‹: {report_type}") 